model:
  name: "LoRaViTRex"
  warmup_fc_only: true
  rank: 10
  layers_to_finetune:
    fc:
      lr: 1e-3
      decay: 0.01
    backbone:
      lr: 1e-4
      decay: 0.001

experiment_name: loravitrex_b_10

training:
  max_epochs: 40
  batch_size: 64
  num_workers: 0

num_classes: 8
size: 224