model:
  name: 'LoRaRexNet'
  rank: 100

experiment_name: lora_101_100

training:
  max_epochs: 40
  batch_size: 64
  num_workers: 0

num_classes: 8
size: 224
