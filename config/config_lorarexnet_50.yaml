model:
  name: 'LoRaRexNet'
  rank: 50

experiment_name: lora_101_50

training:
  max_epochs: 40
  batch_size: 64
  num_workers: 0

num_classes: 8
size: 224
